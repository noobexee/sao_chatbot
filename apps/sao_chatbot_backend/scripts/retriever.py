import asyncio
from typing import List, Optional, Dict, Any
from datetime import datetime

from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from sentence_transformers import CrossEncoder
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field 
from weaviate.classes.query import Filter 
from apps.sao_chatbot_backend.src.app.utils import time_execution
from src.app.llm.typhoon import TyphoonLLM
from src.db.vector_store import get_vectorstore
from dotenv import load_dotenv

load_dotenv()

class SearchIntent(BaseModel):
    """Structure for the optimized legal search query."""
    
    rewritten_query: str = Field(
        description="The query rewritten into formal legal terminology. Combine all intent into one clear sentence. (e.g., Change 'how to submit letter' to 'Criteria for receiving written complaints')"
    )
    law_name: Optional[str] = Field(
        description="Specific law or regulation name if explicitly mentioned. (e.g., '‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏á‡∏¥‡∏ô‡πÅ‡∏ú‡πà‡∏ô‡∏î‡∏¥‡∏ô'). Return None if not mentioned.",
        default=None
    )
    doc_type: Optional[str] = Field(
        description="The type of document explicitly requested (e.g., '‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö', '‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á', '‡∏û‡∏£‡∏ö', '‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®'). Return None if generic.",
        default=None
    )
    search_date: str = Field(
        description="The reference date for the search context in YYYY-MM-DD format."
    )

class Retriever:
    def __init__(self):
        self.vectorstore = get_vectorstore() 
        self.llm = TyphoonLLM().get_model()
        self.reranker = CrossEncoder('BAAI/bge-reranker-v2-m3', device='cpu')
        self.parser = PydanticOutputParser(pydantic_object=SearchIntent)
    @time_execution
    async def generate_search_queries(self, user_query: str, history: List = None) -> Dict[str, Any]:

        if history is None:
            history = []

        current_date = datetime.now().strftime("%Y-%m-%d")


        system_prompt = """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£ (Legal Search Specialist)
        ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ "‡πÅ‡∏õ‡∏•‡∏á" ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (User Query) ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô "‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢" (Legal Search Query) ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        
        ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {current_date}

        ### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á (Instructions):
        1. **‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢:** ‡∏£‡∏ß‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô "‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"
        
        2. **‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏û‡∏π‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£:**
           - ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£ (‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏ö‡∏¥‡∏Å‡πÄ‡∏á‡∏¥‡∏ô" -> "‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏¥‡∏Å‡∏à‡πà‡∏≤‡∏¢")

        3. **‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (Date Handling):**
           - ‡∏´‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô ‡∏û.‡∏®. ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®. (‡∏•‡∏ö 543) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ü‡∏¥‡∏•‡∏î‡πå search_date
           - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: "21 ‡∏°.‡∏Ñ. 2567" -> "2024-01-21"

        4. **‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏•‡∏Ç‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡πÑ‡∏ó‡∏¢ (Thai Numerals) [‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å]:**
           - ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á `rewritten_query` ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏°‡∏≤‡∏ï‡∏£‡∏≤, ‡∏Ç‡πâ‡∏≠, ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏•‡∏Ç‡∏≠‡∏≤‡∏£‡∏ö‡∏¥‡∏Å (0-9) ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡πÑ‡∏ó‡∏¢ (‡πê-‡πô) ‡πÄ‡∏™‡∏°‡∏≠
           - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: "‡∏Ç‡πâ‡∏≠ 39" -> "‡∏Ç‡πâ‡∏≠ ‡πì‡πô"
           - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: "‡∏°‡∏≤‡∏ï‡∏£‡∏≤ 112" -> "‡∏°‡∏≤‡∏ï‡∏£‡∏≤ ‡πë‡πë‡πí"
           - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: "‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏µ‡πà 2" -> "‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏µ‡πà ‡πí"

        5. **Extraction:** ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏´‡∏≤‡∏Å‡∏°‡∏µ

        {format_instructions}
        """
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤:\n{history}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {input}")
        ])

        chain = prompt | self.llm | self.parser

        try:
            # Execute the chain
            response = await chain.ainvoke({
                "input": user_query, 
                "history": history,
                "format_instructions": self.parser.get_format_instructions(),
                "current_date": current_date
            })
            
            return response.dict()

        except Exception as e:
            print(f"‚ö†Ô∏è Query Parsing Failed: {e}")
            return {
                "rewritten_query": user_query,
                "law_name": None,
                "doc_type": None,
                "search_date": current_date
            }

    def _build_filters(self, search_date: str, law_name: str = None, doc_type: str = None):
        filters = []
        if "T" not in search_date:
            rfc3339_date = f"{search_date}T00:00:00Z"
        else:
            rfc3339_date = search_date
            
        date_filter = (
            Filter.by_property("valid_from").less_or_equal(rfc3339_date) & 
            Filter.by_property("valid_until").greater_or_equal(rfc3339_date)
        )
        filters.append(date_filter)

        if law_name:
            filters.append(Filter.by_property("law_name").like(f"*{law_name}*"))

        if doc_type:
             filters.append(Filter.by_property("doc_type").like(f"*{doc_type}*"))

        composite_filter = filters[0]
        for f in filters[1:]:
            composite_filter = composite_filter & f
            
        return composite_filter

    @time_execution
    def _rerank_documents(self, user_query: str, docs: List[Document], top_k: int = 3) -> List[Document]:
        if not docs: return []
        pairs = [[user_query, doc.page_content] for doc in docs]
        scores = self.reranker.predict(pairs)
        doc_score_pairs = list(zip(docs, scores))
        doc_score_pairs.sort(key=lambda x: x[1], reverse=True)
        return [doc for doc, score in doc_score_pairs[:top_k]]

    @time_execution
    async def retrieve(self, user_query: str, history: List = None, k: int = 5, search_date: str = None) -> List[Document]:

        analysis_result = await self.generate_search_queries(user_query, history)
        
        search_queries = analysis_result.get("rewritten_query", "")
        extracted_date = analysis_result.get("search_date")
        law_name_filter = analysis_result.get("law_name")
        doc_type_filter = analysis_result.get("doc_type")

        final_date = search_date if search_date else (extracted_date)
        print(f"search date: {final_date}")

        try:
            time_filter = self._build_filters(
                search_date=final_date,
                law_name=law_name_filter,
                doc_type=doc_type_filter
            )
            if law_name_filter or doc_type_filter:
                print(f"üéØ Sniper Filter Active: Law='{law_name_filter}', Type='{doc_type_filter}'")
        except ValueError as e:
            print(f"‚ö†Ô∏è Filter Error: {e}")
            time_filter = None

        all_docs = []
        
        print(f"Searching: {search_queries} @ {final_date}")
        for query in search_queries:
            docs = self.vectorstore.similarity_search(
                query, 
                k=k, 
                alpha=0.6,
                filters=time_filter 
            )
            all_docs.extend(docs)

        unique_docs_map = {doc.page_content: doc for doc in all_docs}
        unique_candidates = list(unique_docs_map.values())
        
        print(f"Found {len(unique_candidates)} candidates. Re-ranking...")
        final_docs = self._rerank_documents(user_query, unique_candidates, top_k=5)

        return final_docs



async def main():
    query = "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏°‡∏µ‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á"
    
    load_dotenv()
    retriever = Retriever()
    
    try:
        retrieved_docs = await retriever.retrieve(query) 
        if retrieved_docs:
            print(f"\n‚úÖ Found {len(retrieved_docs)} results:\n")
            for i, doc in enumerate(retrieved_docs, 1):
                source = doc.metadata.get("source", "Unknown File")
                law_name = doc.metadata.get("law_name", "N/A")
                valid_from = doc.metadata.get("valid_from", "N/A")
                valid_until = doc.metadata.get("valid_until", "N/A")
                doc_type = doc.metadata.get("doc_type", "N/A")
                
                print(f"{i} Law name: {law_name}")
                print(f"{i} valid_from: {valid_from}")
                print(f"{i} valid_until: {valid_until}")
                print(f"{i} doc_type: {doc_type}")
                print(f"Content: {doc.page_content}") 
                print("-" * 60)
        else:
            print("No documents found.")
            
    finally:
        print("\nClosing connection...")
        if hasattr(retriever.vectorstore, "client"):
            retriever.vectorstore.client.close()
        elif hasattr(retriever.vectorstore, "_client"):
            retriever.vectorstore._client.close()

async def main2():
    query = "‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à ‡πÉ‡∏´‡πâ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£"
    test_date = "2025-12-20"
    
    retriever = Retriever()
    
    print(f"--- Testing retrieverwith date: {test_date} ---")
    
    try:
        retrieved_docs = await retriever.generate_search_queries(query)
        print(retrieved_docs)
        
            
    finally:
        print("\nClosing connection...")
        if hasattr(retriever.vectorstore, "client"):
            retriever.vectorstore.client.close()
        elif hasattr(retriever.vectorstore, "_client"):
            retriever.vectorstore._client.close()

if __name__ == "__main__":
    asyncio.run(main())